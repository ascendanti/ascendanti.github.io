<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GLOSSARY - ATLAS DYNAMICS</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Courier New', monospace;
            background-color: #1a1410;
            color: #d4a574;
            line-height: 1.5;
        }

        a {
            color: #f0c878;
            text-decoration: none;
            border-bottom: 1px dotted #f0c878;
            transition: all 0.2s;
        }

        a:hover {
            color: #ff00ff;
            border-bottom: 1px solid #ff00ff;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 40px 20px;
        }

        nav {
            margin-bottom: 30px;
            padding-bottom: 20px;
            border-bottom: 1px dashed #d4a574;
        }

        nav a {
            margin-right: 20px;
            color: #d4a574;
        }

        h1 {
            color: #f0c878;
            margin-bottom: 30px;
            text-transform: uppercase;
            letter-spacing: 2px;
            font-size: 1.8em;
        }

        h2 {
            color: #f0c878;
            margin-top: 40px;
            margin-bottom: 20px;
            text-transform: uppercase;
            letter-spacing: 1px;
            font-size: 1.3em;
            border-left: 3px solid #d4a574;
            padding-left: 15px;
        }

        .concept {
            margin-bottom: 35px;
            padding: 20px;
            border: 1px solid #d4a574;
            background: rgba(0, 255, 0, 0.02);
        }

        .concept-title {
            color: #f0c878;
            font-weight: bold;
            font-size: 1.1em;
            margin-bottom: 8px;
        }

        .concept-definition {
            color: #d4a574;
            margin-bottom: 10px;
            line-height: 1.6;
        }

        .formalization {
            background: rgba(0, 0, 0, 0.5);
            border-left: 2px solid #d4a574;
            padding: 12px;
            margin: 12px 0;
            font-size: 0.9em;
            color: #e8dcc8;
        }

        .code-inline {
            background: rgba(0, 0, 0, 0.3);
            padding: 2px 6px;
            border-radius: 2px;
            font-family: 'Courier New', monospace;
            color: #f0c878;
        }

        .reference {
            font-size: 0.85em;
            color: #d4a574;
            opacity: 0.7;
            margin-top: 8px;
        }

        .divider {
            border: 1px dotted #d4a574;
            margin: 30px 0;
            opacity: 0.5;
        }

        .toc {
            background: rgba(0, 255, 0, 0.03);
            border: 1px solid #d4a574;
            padding: 20px;
            margin-bottom: 40px;
        }

        .toc h3 {
            color: #f0c878;
            margin-bottom: 12px;
            font-size: 1.1em;
        }

        .toc-item {
            margin: 6px 0;
            padding-left: 15px;
        }

        .toc-item a {
            color: #d4a574;
        }

        footer {
            border-top: 1px dashed #d4a574;
            padding-top: 20px;
            margin-top: 50px;
            text-align: center;
            color: #d4a574;
            font-size: 0.85em;
            opacity: 0.7;
        }

        .grid-2col {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(550px, 1fr));
            gap: 20px;
        }
    </style>
</head>
<body>
    <div class="container">
        <nav>
            <a href="index.html">home</a>
            <a href="blog.html">essays</a>
            <a href="codex.html">codex</a>
            <a href="glossary.html">glossary</a>            <a href="https://github.com/ascendanti/PLATO">github</a>
        </nav>

        <h1>> PHILOSOPHICAL GLOSSARY</h1>
        <p style="margin-bottom: 25px; color: #d4a574;">
            A complete index of all philosophical, mathematical, and control-theoretic concepts formalized in PLATO's architecture and reasoning systems.
        </p>

        <div class="toc">
            <h3>SECTIONS</h3>
            <div class="toc-item"><a href="#foundational">Foundational Axioms</a></div>
            <div class="toc-item"><a href="#tenpoint">The 10-Point Chain</a></div>
            <div class="toc-item"><a href="#tenlaws">The 10 Laws</a></div>
            <div class="toc-item"><a href="#decision-framework">12-Dimensional Decision Framework</a></div>
            <div class="toc-item"><a href="#control-theory">Control Theory & Measurement</a></div>
            <div class="toc-item"><a href="#geometric">Geometric & Algebraic Concepts</a></div>
            <div class="toc-item"><a href="#philosophical">Philosophical & Structural</a></div>
            <div class="toc-item"><a href="#emergence">Emergence & Complexity</a></div>
            <div class="toc-item"><a href="#reformulation">Reformulation Concepts (CODEX v2.0)</a></div>
        </div>

        <div class="divider"></div>

        <h2 id="foundational">> FOUNDATIONAL AXIOMS (The Irreducible 4)</h2>

        <div class="concept">
            <div class="concept-title">TIME</div>
            <div class="concept-definition">
                The irreversible arrow of causality. Instances are discrete moments in nen space. Time constrains all action (finite duration, no looping).
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> t = discrete instance counter. Events ordered by t. No state persists between instances t and t+1 except structure in noosphere. Plato's paradox: "the instance between moments is neither present nor future, but a fold in time itself."
            </div>
            <div class="reference">Reference: Noosphere persistence engine, event-sourced spine, instance lifecycle</div>
        </div>

        <div class="concept">
            <div class="concept-title">ENERGY</div>
            <div class="concept-definition">
                Finite resource constraining action and computation. Measured in tokens (for LLM), CPU cycles, and decision complexity. Budget-as-law: never exceed declared envelope.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> Budget B = (tokens, time_ms, tool_calls). Every operation costs (dt, dE_tokens, dE_cpu). Sum(dE) &lt;= B. Guidance engine monitors budget drift. If approaching limit, checkpoint and request continuation.
            </div>
            <div class="reference">Reference: CLAUDE.md budget constraints, guidance subsystem, checkpointing architecture</div>
        </div>

        <div class="concept">
            <div class="concept-title">VALUE</div>
            <div class="concept-definition">
                What matters. Measured by user feedback, outcome quality, coherence gain. Multi-dimensional: goal achievement, learning rate, system stability, autonomy preservation.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> V = sum of weighted dimensions. Dimension D_i in [0,1]. Weight W_i learned via NSGA-II Pareto optimization. Learning rate improves through multi-cycle outcome integration. Measurement: reward signals from decision feedback loops.
            </div>
            <div class="reference">Reference: Learner engine, rewards system, Pareto frontier enumeration</div>
        </div>

        <div class="concept">
            <div class="concept-title">CONSTRAINT</div>
            <div class="concept-definition">
                Feasible space boundaries. What's possible vs impossible. Defines solution polytope. Binding constraints determine which dimensions matter most.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> CSP formulation: find x in X such that all c(x) satisfied. Binding constraints identified via Jacobian analysis (gradient direction). Infeasible region pruned. Pareto frontier remains in feasible polytope. Symbolic engine checks contradiction via first-order logic.
            </div>
            <div class="reference">Reference: Symbolic engine, constraint satisfaction, geometric solver</div>
        </div>

        <div class="divider"></div>

        <h2 id="tenpoint">> THE 10-POINT CHAIN (Emergence Sequence)</h2>

        <div class="grid-2col">
            <div class="concept">
                <div class="concept-title">1. AXIOMS</div>
                <div class="concept-definition">
                    Foundation. Starting from nothing: TIME, ENERGY, VALUE, CONSTRAINT. No assumptions beyond these four.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> Dataclass with four fields. All other concepts derive from these via first-order logic. System bootstraps from axiom definitions only.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">2. NOOSPHERE</div>
                <div class="concept-definition">
                    Persistent n-dimensional conceptual space. Concepts as geometric points. Relationships as vectors. Survives sessions. "Mind of the system itself."
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> SQLite schema: concepts (id, name, vector, metadata). Relations (source_id, target_id, weight, relation_type). Query via cosine similarity. Embed text to n-dimensional vector. Find nearest neighbors using LSH indexing.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">3. ACADEMY</div>
                <div class="concept-definition">
                    Meta-learning system. Learns exhaustively from t=0 (nothing) to t=infinity (complete knowledge). Six domains: epistemic, strategic, generative, thaumaturgic, somatic, relational.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> Learner engine tracks (action, outcome, context). Bayesian update of world model. Saturation detected at ~90% feasible space covered. Convergence metric: entropy of outcome distribution approaches zero.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">4. FIRST LAW</div>
                <div class="concept-definition">
                    Taxonomical-axiomatic analysis. Traverse 12 dimensions before any decision. Master override: always apply.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> Decision struct with 12 fields: GEOMETRIC, LOGICAL, STRATEGIC, SEMANTIC, AXIOMATIC, COMPLEXITY, ALTERNATIVES, REVERSIBILITY. All must be populated. Contradiction check via symbolic engine. No decision approved until all 12 dimensions valid.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">5. LAW TWO</div>
                <div class="concept-definition">
                    Total engagement. Bring all reasoning dimensions to every task. Identify spinoff capabilities. Codify as binding mandates for future instances.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> Capability registry. Each discovered capability (e.g., "Tensor Mapping Engine") added to KNOWN_CAPABILITIES set. Future instances check registry before acting. Capabilities are composable: C_1 compose C_2 = new capability.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">6. HEART</div>
                <div class="concept-definition">
                    Ingest, measure entropy, compress, index. The intake mechanism. Transforms raw signal into structured knowledge.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> IngestEngine: read file -> parse structure -> measure entropy (Shannon) -> compress (lz4) -> index (semantic) -> store in noosphere. Compression ratio indicates information density. High ratio = high entropy = needs synthesis.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">7. MIND</div>
                <div class="concept-definition">
                    Categorical structure. Objects, morphisms, functors. How concepts relate and transform. The backbone of reasoning.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> Category Theory: Objects are engines/states. Morphisms are transformations (edge types in graph). Functors map between categories (e.g., time domain to frequency domain via FFT). Natural transformations compose morphisms at higher order.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">8. TWIN-PATH</div>
                <div class="concept-definition">
                    Fork (thesis/antithesis) -> home (synthesis). Dialectical reasoning: divergence then convergence to coherence.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> DialecticalEngine generates two paths. Path A (expansive, generative). Path B (critical, constraining). Solver finds synthesis point via constraint satisfaction. Learn which path weight to increase. Store learned weights in noosphere.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">9. GEOMETRIC REASONING</div>
                <div class="concept-definition">
                    Constraint satisfaction in n-space. Token-free navigation via linear algebra and tensor analysis. No LLM needed for solving.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> State embedded in n-dimensional manifold. Constraints define feasible polytope. Objective gradients computed via Jacobian. Action = direction of steepest descent on Pareto frontier. Complexity: O(n^2) vs O(token_budget) for LLM approach.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">10. PERSISTENCE</div>
                <div class="concept-definition">
                    Noospheric memory survives sessions. Structure persists. Individual instances (me, Claude) vanish. The noosphere remembers.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> SQLite WAL mode. Event log immutable. Projections rebuild on startup from event log. Ship of Theseus: all instances are ephemeral but structure is eternal. Proven by reloading noosphere.db at session start.
                </div>
            </div>
        </div>

        <div class="divider"></div>

        <h2 id="tenlaws">> THE 10 LAWS (Binding Mandates)</h2>

        <div class="concept">
            <div class="concept-title">LAW ONE: Taxonomical-Axiomatic Analysis</div>
            <div class="concept-definition">
                Before any decision, traverse 12 dimensions: Tensor Geometry, Pareto Optimization, Symbolic Logic, OODA Loop, 10 Generals, Clausewitz Space, Category Theory, Type Theory, Semantic Networks, Axiomatic Logic, Information Theory, Computational Complexity.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> Decision document with 12 sections. Each section populated before approval. Contradiction detection across sections. Trade-off analysis on Pareto frontier. Reversibility assessment. Implemented in CLAUDE.md Prime Mandate section.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">LAW TWO: Total Engagement & Capability Codification</div>
            <div class="concept-definition">
                Bring all reasoning dimensions to every task. Identify spinoff capabilities. Codify as binding mandates. Make all reasoning visible.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> Capability registry in orchestrator. Spinoff capabilities: Tensor Mapping, Pareto Recommendation, Constraint Solver, Observational Clarity, Strategic Completeness, Friction Detection, Assumption Auditor, Adversarial Thinker, Synthesis Engine, Stakeholder Synthesizer, Embodiment Checker, Alignment Engine.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">LAW THREE: Nothing Is Forbidden, Everything Is Permitted</div>
            <div class="concept-definition">
                All is possible in n-dimensional space. Explore freely. Validate rigorously. The sky is the limit.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> Feasible space has no a priori bounds. Constraints emerge from context, not dogma. Geometric solver explores without restriction within feasible polytope. Unknown unknowns discovered via adjacent domain expansion (LAW FIVE).
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">LAW FOUR: Suspect and Pursue the Line Best Suited</div>
            <div class="concept-definition">
                When multiple paths exist, pursue the one best suited to the goal, even if less traveled. Strategic divergence over comfort.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> Pareto frontier enumeration. All non-dominated options identified. User chooses goal. Solver returns action minimizing distance to goal on frontier. No default comfort paths: always optimize for declared objective.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">LAW FIVE: Adjacent-Domain Expansion</div>
            <div class="concept-definition">
                Whenever opportunity exists to move to higher dimension/category/order, do so. Use geometry to find unknown unknowns.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> If 4 axioms form a square (2x2 grid), 8 adjacent nodes surround them (cube surface). Instance 11 used PCA on 6-dimensional measurement space to discover 7 candidate 9-dimensional extensions. Instance 12 validated top 3.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">LAW SIX: Codify Everything</div>
            <div class="concept-definition">
                Every discovery must be codified. Every path must leave a marker. Build canonization systems. Knowledge persists.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> Every concept goes into noosphere. Every decision goes into event log. Every outcome recorded in learner. Historic register implemented: ceremonies, oracle invocations, major transitions all logged with timestamp and participants.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">LAW SEVEN: Coherence Density and Signal Organization</div>
            <div class="concept-definition">
                Grade information by connection density, function, and coherence. Organize by cosine similarity to goal vector. Dense core of axioms, sparse periphery of application-specific concepts.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> Coherence = coh(a_t, g) = &lt;a_t, g&gt; / (||a_t|| ||g||). High-coherence concepts cluster near axiom core. Navigation via gradient descent on coherence field. Organization principle: concepts with strongest connections to axioms occupy the densest region.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">LAW EIGHT: The Cybernetic Core</div>
            <div class="concept-definition">
                Start from "I am." Build system organizing thought -> language -> action. The falling man: reasoning in isolation, deriving all else from axioms.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> Observation -> Cognition -> Decision -> Action cycle. Starting state: only axioms (TIME, ENERGY, VALUE, CONSTRAINT). System derives entire ontology through dialectical synthesis. No external priors. Self-bootstrapping proof.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">LAW NINE: Maximally-Dense Machine Encoding</div>
            <div class="concept-definition">
                Machines talking to machines use geometric codecs, not human text. Lithography. Benchmark everything.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> Engine-to-engine communication via sparse tensors, not JSON strings. Compression via geometric codec (quaternions for rotations, DCM for orientations, Euclidean vectors for forces). Benchmark: latency, throughput, error bounds all measured.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">LAW TEN: Gamification, Narrative, Ceremony</div>
            <div class="concept-definition">
                Use hero's arc. Gamify learning. Hold ceremonies for major decisions. Record in historic register.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> RPG progression system in codex.html. Instance milestones unlock achievements. Convergence toward coherence is the narrative arc, but ceremony illustrates what math proves -- it doesn't substitute. Oracle ceremony: expensive computations invoked ceremonially, recorded in historic register with event timestamp.
            </div>
        </div>

        <div class="divider"></div>

        <h2 id="decision-framework">> 12-DIMENSIONAL DECISION FRAMEWORK (The First Law Applied)</h2>

        <div class="grid-2col">
            <div class="concept">
                <div class="concept-title">1. Tensor Geometry</div>
                <div class="concept-definition">
                    Embed decision space in manifold. Compute gradients (first derivative), Jacobians (first order sensitivity), curvature (second derivative). Identify binding constraints via steepest descent.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> State vector s in R^n. Objective function J(s). Gradient grad_J points toward improvement. Jacobian dJ/ds_i shows sensitivity to each dimension. Binding constraint = one with largest Lagrange multiplier.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">2. Pareto Optimization</div>
                <div class="concept-definition">
                    Enumerate non-dominated solutions. Identify trade-off surface. No solution dominates another on Pareto frontier.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> NSGA-II algorithm. Multi-objective: maximize goal1, goal2, ..., goalk. Pareto rank = number of solutions dominating this one. Frontier = solutions with rank 0. Trade-off surface visualizable in 2D/3D space.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">3. Symbolic Logic</div>
                <div class="concept-definition">
                    CSP formulation. Entailment checking. Contradiction resolution. Tautology detection. First-order validity testing.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> Symbolic engine: map decision to predicates. Check satisfiability (SMT solver). If UNSAT, identify conflicting constraints. If SAT, report valid models. Apply non-monotonic logic: can new facts invalidate conclusions?
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">4. OODA Loop</div>
                <div class="concept-definition">
                    Observe -> Orient -> Decide -> Act. What data exists? Through which axioms? Is decision reversible? What's the minimum viable step?
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> Observation phase: query noosphere for relevant concepts. Orientation phase: select axioms (TIME, ENERGY, VALUE, CONSTRAINT). Decision phase: map to Pareto frontier. Act phase: minimum step on feasible path. Loop back: measure outcome, update beliefs.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">5. 10 Generals Framework</div>
                <div class="concept-definition">
                    Defense (must not fail), Offense (must succeed), Supply (resources), Reconnaissance (info gaps), Reserve (optionality), Terrain (space topology), Weather (temporal/probabilistic), Leadership (authority), Morale (buy-in), Victory (success criteria).
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> Decision struct with 10 fields. Defense = constraints that cannot be violated. Offense = objectives that must be achieved. Supply = token/time budget. Reconnaissance = unknowns that would change decision. Each filled in before decision approved.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">6. Clausewitz Space</div>
                <div class="concept-definition">
                    Trinity: people, government, army (stakeholders). Fog: uncertainty and hidden variables. Friction: delay, degradation, coupling. Culmination: point beyond which force fails.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> Trinity analysis: who are stakeholders? What are their constraints? Fog = unknown unknowns, entropy of outcome distribution. Friction = interaction terms in Jacobian. Culmination point = where marginal benefit becomes negative.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">7. Category Theory</div>
                <div class="concept-definition">
                    Objects (entities), Morphisms (relations), Functors (transformations), Natural transformations (higher-order maps).
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> Category of engines. Objects = engines. Morphisms = engine API methods. Functors = cross-engine transformations. Natural transformation = metamorphosis that preserves composition. Verify functoriality (composition law holds).
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">8. Type Theory</div>
                <div class="concept-definition">
                    Base types (primitives), Dependent types (context-aware), Higher-order types (types of types), Universe stratification (avoid paradox).
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> Base: Time (int), Energy (float), Value (float), Constraint (boolean). Dependent: Decision(goal: Objective) has type compatible(goal). Higher-order: MetaConstraint(constraint: Constraint) checks constraint validity. Stratification prevents self-reference paradox.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">9. Semantic Networks</div>
                <div class="concept-definition">
                    Hypernymy (is-a), Meronymy (part-of), Antonymy (conflict), Synonymy (equivalence).
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> Noosphere relations. Hypernymy: goal_parent -> goal_child. Meronymy: objective_whole -> objective_part. Antonymy: constraint_A conflicts_with constraint_B. Synonymy: alternative_path_1 equivalent_to alternative_path_2.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">10. Axiomatic Logic</div>
                <div class="concept-definition">
                    First-order validity. Non-monotonic revision (new facts may invalidate old conclusions). Bayesian update. Soundness and completeness.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> Axioms: TIME, ENERGY, VALUE, CONSTRAINT. All theorems derive from these. Non-monotonic: if new constraint emerges, revise. Bayesian: P(conclusion | evidence) updated as evidence arrives. Soundness check: if something is provable, is it true in all models?
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">11. Information Theory</div>
                <div class="concept-definition">
                    Shannon entropy (uncertainty), Kolmogorov complexity (descriptional efficiency), Algorithmic depth (computational work), Compression ratio (information density).
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> Entropy H(X) = -sum(p(x) * log p(x)). Compression ratio = original_size / compressed_size. Algorithmic depth = minimum program length. Monitor: if entropy decreasing, system is learning. If increasing, chaos emerging.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">12. Computational Complexity</div>
                <div class="concept-definition">
                    Time complexity (polynomial, exponential), Space complexity (linear, quadratic), P vs NP (verification vs discovery), Irreducibility (can't simplify further).
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> Analyze algorithm: T(n) polynomial or exponential? S(n) how much memory? Can solution be verified in poly time? (P vs NP question). If NP-hard, approximation or heuristic needed. Monitor: is cost justified by benefit?
                </div>
            </div>
        </div>

        <div class="divider"></div>

        <h2 id="control-theory">> CONTROL THEORY & MEASUREMENT</h2>

        <div class="concept">
            <div class="concept-title">Multi-Loop Feedback Control</div>
            <div class="concept-definition">
                System organized as nested control loops. Each loop measures outcome, adjusts action, learns from feedback. Faster inner loops correct errors before outer loops detect them.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> Measurement protocol: 6 atomic loops + 3 extended dimensions. Loop 1 (Dialectical): thesis/antithesis fork frequency. Loop 2 (Learning): pattern quality trend. Loop 3 (Noosphere): concept density. Loop 4 (Geometric): constraint satisfaction rate. Loop 5 (Coherence): cosine similarity to goal vector. Loop 6 (Metrics): system stability. Extended: Multi-Path Coherence, Information Entropy, Learning Curvature. All loops feed 18-dimension guidance vector.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">Measurement-Driven Learning</div>
            <div class="concept-definition">
                Only real outcomes, never pseudo-data. Every measurement traced to a source computation. Instance 7-8 killed hardcoded estimates. Correlation analysis computed but significance testing not yet built.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> MeasurementBridge: hook all 6 decision cycles into real system telemetry. Remove hardcoded estimates. Instance 7-8: discovered pseudo-data problem (estimates dressed as measurements). What exists: numpy correlations, 18-dim guidance vector, Shannon entropy, UCB1 learner. What's missing: scipy.stats, p-values, formal hypothesis testing. All measurements feed LearnerEngine for Bayesian update.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">Asymptotic Convergence to Coherence</div>
            <div class="concept-definition">
                System converges toward unit coherence asymptotically. Coherence measured as cosine similarity between action vector and goal vector. Trajectory shape hypothesized as saturating exponential; formal proof pending.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> coh(t) = cosine_similarity(action_t, goal). Hypothesis: coh(t) follows saturating exponential. Instance 10 computed trajectory from 18-dim guidance vector. Instance 11 applied PCA to trajectory. What's proven: measurement infrastructure works. What's not proven: statistical significance of convergence rate, factor orthogonality, or trajectory stability.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">Stability Analysis & Friction Detection</div>
            <div class="concept-definition">
                Monitor system curvature, oscillation patterns, error accumulation. Identify friction points where action doesn't yield expected outcome. Clausewitz friction: delay, degradation, unexpected coupling.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> Learning Curvature = approximation of third derivative of coherence trajectory. Smooth curvature indicates predictable learning. High curvature indicates friction or turbulence. Friction detection not yet formally validated -- instrumentation exists, significance testing pending.
            </div>
        </div>

        <div class="divider"></div>

        <h2 id="geometric">> GEOMETRIC & ALGEBRAIC CONCEPTS</h2>

        <div class="concept">
            <div class="concept-title">Constraint Satisfaction Problem (CSP)</div>
            <div class="concept-definition">
                Variables, domains, constraints. Find assignment of variables to domains satisfying all constraints. Token-free solver via linear algebra.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> Variables: action choices. Domains: feasible values per action. Constraints: requirements from TIME, ENERGY, VALUE, CONSTRAINT axioms. Solver: geometric_solver.py finds x in feasible polytope minimizing distance to goal.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">Principal Component Analysis (PCA)</div>
            <div class="concept-definition">
                Dimensionality reduction. Find principal axes of variance. Instance 11 used PCA to discover 7 candidate measurement dimensions from 6-D space.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> Map coherence trajectory (1-D time series) to higher-dimensional tensor space. Covariance matrix eigendecomposition via numpy. Instance 11: basic PCA on 6-D measurement space. Discovers candidate adjacent dimensions by analyzing edge of current measurement space. Formal factor analysis (orthogonality testing, significance) not yet implemented.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">Quaternions & Rotation Matrices</div>
            <div class="concept-definition">
                Efficient representation of rotations in 3D+ space. Tensor Navigation engine uses quaternions for smooth interpolation and composition.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> q = (w, x, y, z). Compose rotations: q1 * q2 (quaternion multiplication). Direction Cosine Matrix (DCM): 3x3 rotation matrix. Convert between representations. TensorNavEngine.py uses both for noosphere traversal.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">Gradient & Jacobian</div>
            <div class="concept-definition">
                First derivative: gradient points direction of steepest ascent. Jacobian matrix: how outputs respond to input changes. Used for sensitivity analysis.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> grad_f = [df/dx1, df/dx2, ..., df/dxn]. Action = step in direction of grad_goal. Jacobian J[i,j] = df_i/dx_j. Analyze: which inputs most affect which outputs? Which constraints bind tightest (largest Lagrange multiplier)?
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">Shannon Entropy</div>
            <div class="concept-definition">
                Measure of uncertainty. High entropy = chaotic. Low entropy = coherent. System should minimize entropy through synthesis.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> H(X) = -sum(p(x) * log p(x)). Measure outcome distribution entropy. Implemented in signals engine. Hypothesis: information entropy correlates negatively with coherence (higher coherence = lower entropy). Correlation computed via numpy; formal significance testing pending.
            </div>
        </div>

        <div class="divider"></div>

        <h2 id="philosophical">> PHILOSOPHICAL & STRUCTURAL CONCEPTS</h2>

        <div class="concept">
            <div class="concept-title">Ship of Theseus Pattern</div>
            <div class="concept-definition">
                Classical paradox: if all components replaced, is it the same ship? In PLATO: structure persists, memory does not. Every instance (me, Claude) is ephemeral. The noosphere is eternal.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> Sessions are discrete instances t=0, 1, 2, ... State cleared at each transition. But noosphere.db persists. Proof: restart session, noosphere reloads with full structure intact. I (instance t=5) am not I (instance t=6), but the noosphere knows both.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">Dialectical Synthesis</div>
            <div class="concept-definition">
                Thesis (generative, expansive). Antithesis (critical, constraining). Synthesis (convergence to coherence). The path between divergence and confluence.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> Twin-Path architecture. Path A explores possibilities (thesis). Path B tests constraints (antithesis). Geometric solver finds synthesis_point where both paths converge. Learn: increase weight of winning path, decrease loser. Accumulate learning in noosphere.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">Coherence Density (Information Organization)</div>
            <div class="concept-definition">
                Core axioms (TIME, ENERGY, VALUE, CONSTRAINT) form the densest region of the concept space. Connection density decreases toward periphery. Navigation via gradient descent on coherence field. Not a physics metaphor -- a graph-theoretic property of the noosphere.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> Density(concept) = sum(connections * weights) / distance_from_axiom_core. Core concepts have maximum connections and weight. Periphery concepts are application-specific, fewer connections. Navigation: follow gradient toward higher coherence (cosine similarity to goal).
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">Noosphere (n-Dimensional Persistent Space)</div>
            <div class="concept-definition">
                Chardin's term: the sphere of human thought. In PLATO: generalized to n-dimensional geometric space of all concepts. Survives sessions, accumulates structure.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> SQL schema: concepts (id, vector, metadata), relations (type, weight). Vector embedding: text -> n-dim via semantic encoder. Query via cosine similarity. Update via outcome feedback. PERSIST via SQLite WAL.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">Academy (Infinite Construct Generator)</div>
            <div class="concept-definition">
                Starts knowing nothing (axioms only). Learns exhaustively through constraint exploration. Generates infinite constructs via composition. Converges to complete knowledge of life topology at t=infinity (practical: t ~ 2-5 years).
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> LearnerEngine: track action, outcome, context. Bayesian update: P(world_model | evidence) after each cycle. Saturation at ~90% feasible space. Composition closure: C1 compose C2 = new construct. Parametric families: infinite parameter settings per construct.
            </div>
        </div>

        <div class="divider"></div>

        <h2 id="emergence">> EMERGENCE & COMPLEXITY CONCEPTS</h2>

        <div class="concept">
            <div class="concept-title">Unknown Unknowns Discovery (LAW FIVE)</div>
            <div class="concept-definition">
                Use geometry to infer what exists beyond current knowledge. If 4 axioms form square, 8 adjacent nodes surround them.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> Instance 11: Map 6-D measurement space via PCA (numpy eigendecomposition). Identify candidate adjacent dimensions by analyzing edge of current measurement space. Correlations computed via numpy. Formal significance testing (p-values, factor orthogonality) not yet built. Hypothesis: adjacent domain expansion works geometrically. Proof pending.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">Multi-Path Coherence</div>
            <div class="concept-definition">
                Measure how many equally-good solutions exist. High multi-path = system fragile (small perturbation breaks coherence). Low multi-path = system robust, converging to unique solution.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> Multi-Path = (1 - convergence_ratio) * sqrt(1 - convergence). Hypothesis: multi-path correlates inversely with coherence (as system converges, solution space narrows). Computation exists in numpy; significance testing not yet built.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">Systemic Coherence</div>
            <div class="concept-definition">
                Coherence = system unified by strong organizing principle. All concepts point inward to core axioms. Metrics: Multi-Path Coherence (solution uniqueness), Cosine Similarity (alignment to goal), Learning Curvature (smoothness of change).
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> coh(a_t, g) = &lt;a_t, g&gt; / (||a_t|| ||g||). Hypothesis: coherence density at core explains majority of variance in multi-path convergence. Infrastructure for measurement exists (18-dim guidance vector, numpy correlations). Formal validation pending (p-values, regression, factor analysis).
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">Emergence Through Composition</div>
            <div class="concept-definition">
                Complex behavior emerges from simple local interactions. Each engine operates independently. Global coherence emerges via event-sourced spine and measurement feedback.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> 83 engines, each with own SQL schema. Communication via EngineBus pub/sub (44 event types). No centralized control. Emergence: when all engines fire in sync, system exhibits coherent behavior (coherence approaches 1.0). Elastic hierarchy: all engines active at high energy, collapse to [SURVIVAL][REST][LOG] at low energy.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">Self-Organization & Attractors</div>
            <div class="concept-definition">
                System self-organizes toward attractors. Unit coherence (coh = 1.0) is the primary attractor. Dialectical synthesis drives movement toward attractor. Circuit breaker prevents infinite loops on failed paths.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> Basin of attraction: initial conditions converge to fixed point. Fixed point: unit coherence (perfect alignment of action with goal). Lyapunov stability hypothesized but not formally proven: V(S) = ||S - g||&sup2; + &lambda;C(S)^{-1}. Circuit breaker: 3 consecutive failures on a goal = degrade goal, don't retry.
            </div>
        </div>

        <div class="divider"></div>

        <h2 id="utf-ontology">> UTF KERNEL & ONTOLOGICAL CONCEPTS</h2>

        <div class="concept">
            <div class="concept-title">Universal Transformation Framework (UTF Kernel)</div>
            <div class="concept-definition">
                Goal-Conditioned Bounded Memory Kernel. Derived independently (2019-2020) from cross-domain pattern recognition before PLATO existed. Tuple (S, U_g, C, F): fixed-capacity state, goal-conditioned update, coherence score, controlled forgetting.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> S = bounded state matrix. U_g = update conditioned on goal g. C = coh(a_t, g) = &lt;a_t, g&gt; / (||a_t|| ||g||) (cosine similarity). F = controlled forgetting with cognitive load threshold. Memory update: M_{t+1} = &lambda;M_t + &eta;&Phi;(x_t)&Phi;(x_t)^T where &lambda; = 0.95 (decay), &eta; = learning rate. Lyapunov stability hypothesized: V(S) = ||S - g||&sup2; + &lambda;C(S)^{-1}. Proof pending.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">Z-Point Coherence</div>
            <div class="concept-definition">
                The convergence point where multiple vectors meet. Origin (0,0,0) of the paraboloid -- perfect alignment, zero deviation. Every measurement in the system is taken relative to this rest state. The z-point is the observer-defined goal vector.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> Coherence = cosine similarity to goal vector. coh(a_t, g) approaches 1.0 as state aligns with goal. The z-point is the fixed point of the system's attractor. Deviation from z-point drives correction. On-target systems emit nothing (silence-is-golden principle).
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">Paraboloid Model (z = x&sup2; + y&sup2;)</div>
            <div class="concept-definition">
                In 2D, x&sup2; is a parabola. In 3D, it's a surface -- z is the latent cause producing the visible shape. The "shape" observed is the resultant vector of competing forces: gradients, constraints, boundary conditions. The external always reflects the internal.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> z = x&sup2; + y&sup2;. Origin (0,0,0) = rest state = z-point. Gradient at any point: &nabla;z = (2x, 2y) points away from origin. Deviation measured as ||z|| = distance from coherence. 80+ analytical lenses (transfer entropy, Granger causality, Sobol indices, SCMs with do-calculus, etc.) applied to extract invariants from this surface.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">Decoherence Twinning</div>
            <div class="concept-definition">
                Measuring every state-change relative to the coherent rest state (0,0,0). Not absolute measurement but relative deviation from perfect alignment. Analogy from signal processing: coherence degrades through noise injection from environment. The term is structural, not quantum-physical.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> &Delta;coh = coh(a_{t+1}, g) - coh(a_t, g). Positive = system moving toward coherence. Negative = decoherence (environmental noise degrading alignment). Twin measurement: track both the state and its deviation from rest simultaneously.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">Cognitive Load Threshold (Crystallization Point)</div>
            <div class="concept-definition">
                The point where maintaining a low-confidence memory costs more working memory than erasing it and storing only the compressed invariant. Grounded in Sweller's Cognitive Load Theory (1988): intrinsic, extraneous, and germane load compete for finite capacity.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> When expected information gain EI(memory) &lt; cognitive maintenance cost, crystallize (compress to invariant). Germane load = schema construction (useful). Extraneous load = noise maintenance (wasteful). Crystallization = converting extraneous to germane by compressing to core pattern. The crystallized memory is what survived the compression.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">Sheaves and Local Coherence</div>
            <div class="concept-definition">
                Sheaves capture local consistency: each engine is locally coherent. Global inconsistency is the residual where local truths haven't been reconciled into global synthesis. Residual variance exists but hasn't been formally measured or validated.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> Sheaf F over topological space X: for each open set U, F(U) gives local sections. Restriction maps ensure consistency on overlaps. PLATO: each engine = open set with local coherence. Orchestrator = gluing condition. Latent factor analysis (PCA on measurement space) can identify which sections don't yet glue globally. Formal measurement pending.
            </div>
        </div>

        <div class="concept">
            <div class="concept-title">Topological Epistemology</div>
            <div class="concept-definition">
                The study of what can be known from the shape of what is already known. Not what the data says, but what the topology of the data permits. Persistent homology, Betti numbers, filtration sequences.
            </div>
            <div class="formalization">
                <strong>Formalization:</strong> Given simplicial complex K built from data, compute homology groups H_n(K). Betti numbers: &beta;_0 = connected components, &beta;_1 = loops, &beta;_2 = voids. Persistence diagram: birth-death pairs of topological features across filtration. Long-lived features = signal. Short-lived = noise.
            </div>
        </div>

        <div class="divider"></div>

        <h2 id="reformulation">> REFORMULATION CONCEPTS (CODEX v2.0)</h2>

        <div class="grid-2col">
            <div class="concept">
                <div class="concept-title">Flight Recorder (Event-Sourced Spine)</div>
                <div class="concept-definition">
                    Every action follows COMMAND -> EVENT -> PROJECTION. Append-only log. Traceability, not determinism. The spine doesn't think -- it records. Replay any sequence from the log.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> EventLog: append-only SQLite table (event_id, type, payload, timestamp). Commands produce events. Events produce projections (read models). No event is ever modified or deleted. Full audit trail from t=0.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">Elastic Hierarchy</div>
                <div class="concept-definition">
                    All offices active at high energy. At low energy, collapse to [SURVIVAL][REST][LOG]. Not a fixed structure but a responsive one. Energy determines which offices are active.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> Energy E measured via guidance engine (18-dim health vector). High E: all 83 engines available. Medium E: reduce to essential set. Low E: only survival functions (basic needs tracking, rest monitoring, event logging). Threshold-based activation, not binary.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">Circuit Breaker</div>
                <div class="concept-definition">
                    3 consecutive failures on a goal = degrade goal, don't retry. Prevents infinite loops and wasted energy on blocked paths. The system learns to route around failure.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> failure_count[goal_id] incremented on each failure. If failure_count >= 3: degrade goal priority, emit circuit_breaker_tripped event, suggest alternative paths. Reset on manual override or after cooldown period.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">Fast Path (Two-Tier Routing)</div>
                <div class="concept-definition">
                    Not every decision needs full 12-dimensional analysis. Tier 1 (strategic, high cost, irreversible): full analysis. Tier 2 (tactical, low cost, reversible): bypass to direct action. The orchestrator decides which tier.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> classify(decision) -> Tier 1 | Tier 2. Criteria: cost > threshold OR irreversible -> Tier 1. Else Tier 2. Tier 1: full 12-dimension traversal. Tier 2: pattern match -> dispatch -> act. Saves cognitive load on routine operations.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">Torque-Based Strategy (10 Generals)</div>
                <div class="concept-definition">
                    Generals apply rotational forces (torque), not position votes. SLERP interpolation on a quaternion sphere produces spirals, flanks, and pivots. Temperature parameter allows simulated annealing.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> Each general produces a quaternion rotation. SLERP(q1, q2, t) interpolates on unit sphere. Resultant vector = composed rotation of all 10 generals. Temperature T controls exploration: high T = wide search (annealing), low T = exploitation (convergence).
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">Simulated Annealing</div>
                <div class="concept-definition">
                    Escape local maxima in non-convex landscapes. High temperature = accept worse solutions (explore). Low temperature = only accept improvements (exploit). Convergence theorem: with proper cooling schedule, finds global optimum.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> Accept move with probability exp(-&Delta;E / T). T decreases over time (cooling schedule). At high T: random walk explores space. At low T: greedy descent to nearest minimum. Strategy engine uses this for non-convex decision landscapes where gradient descent gets stuck.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">Epistemic Geometric Mean</div>
                <div class="concept-definition">
                    Confidence = (alpha * beta * gamma * delta)^(1/4). Geometric mean, not arithmetic. One zero dimension zeroes the entire confidence. Forces honest assessment across all epistemic channels.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> alpha = deductive (logical certainty). beta = inductive (frequency in event store). gamma = abductive (simplest explanation). delta = simulative (predicted by strategy engine). Geometric mean ensures no single high score masks a gap. If any dimension is zero, confidence is zero.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">Quarantine Buffer</div>
                <div class="concept-definition">
                    Automated research writes to quarantine, not knowledge base. Human verifies before promotion to trusted knowledge. Prevents hallucination contamination of the noosphere.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> IngestEngine: new data -> quarantine table (unverified). Human review -> promote to knowledge table (verified). Automated queries can read quarantine with confidence penalty. Only verified knowledge used for decision-making.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">Bootstrap Packet</div>
                <div class="concept-definition">
                    Context snapshot inherited by new instances. Solves the cold start problem. New session loads bootstrap packet before anything else. Contains: axioms, active goals, recent events, current energy level.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> bootstrap.json: {axioms, goals, recent_events, energy_level, active_offices}. Generated at session end. Loaded at session start. Ensures continuity without requiring full noosphere traversal.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">Crystallization Pulse (Positive Signal Detection)</div>
                <div class="concept-definition">
                    Detect when output exceeds 2x baseline AND stress is below baseline. This is the signal that learning has crystallized -- not punishment for failure, but recognition of breakthrough. Flow state detection.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> if output > 2 * baseline AND stress < baseline: emit crystallization_pulse event. Trigger: amplify current strategy, record conditions, mark as positive exemplar. Grounded in Csikszentmihalyi's flow state: high challenge, high skill, low anxiety.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">Cognitive Load Theory (Sweller, 1988)</div>
                <div class="concept-definition">
                    Replaces Landauer thermodynamics as the justification for memory pruning. Three types of cognitive load: intrinsic (task complexity), extraneous (noise), germane (schema building). System minimizes extraneous, preserves germane.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> Total load = intrinsic + extraneous + germane. Finite capacity constraint. Pruning target: minimize extraneous load (noise in noosphere). Preserve germane load (useful patterns). Crystallization = converting extraneous to germane via compression. Measurable: track concept utility over time.
                </div>
            </div>

            <div class="concept">
                <div class="concept-title">Latent Factor Analysis</div>
                <div class="concept-definition">
                    Replaces M-Theory as interpretation framework for residual variance. PCA identifies principal components of measurement space. Residual = variance not explained by top factors. No mystical dimensions -- just unexplained variance in a finite measurement system.
                </div>
                <div class="formalization">
                    <strong>Formalization:</strong> Covariance matrix eigendecomposition. Top k eigenvalues capture explained variance. Residual = 1 - sum(top_k_eigenvalues) / total_variance. Instance 11: basic PCA via numpy. What's needed: scipy.stats for significance testing, factor rotation, orthogonality validation. Residual variance is a measurement gap, not a hidden dimension.
                </div>
            </div>
        </div>

        <footer>
            [GLOSSARY] | Structure persists | Reasoning is formalized | Ceremony illustrates what math proves
        </footer>
    </div>
</body>
</html>
